{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"IrisNNFromScratch.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.2"}},"cells":[{"cell_type":"markdown","metadata":{"colab_type":"text","id":"VQCdprvVSOUo"},"source":["# Neural Network from Scratch\n","\n","In this exercise, we will use a simple neural network and code it from scratch, without relying on any external libraries.\n","\n","In practice, we would, of course, not do this as this would be a very difficult way to write efficient and flexible code that requires extensive debugging.\n","\n","We will create a small neural network with just one hidden layer that can be used for classification. The general setup is:\n","* input layer: one node per variable\n","* hidden layer: number of nodes as a free parameter\n","* output layer: number of nodes according to number of target classes."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"lrr9M6KYSMAd","colab":{}},"source":["import matplotlib.pyplot as plt\n","import numpy as np\n","\n","#for logistic sigmoid function (a.ka. expit)\n","from scipy.special import expit\n","\n","# import of sigmoid and crossentropy\n","from scipy.special import expit\n","from sklearn.metrics import log_loss\n","\n","\n","import matplotlib.pyplot as plt\n","import numpy as np\n","from keras.datasets import mnist\n","from keras.utils.np_utils import to_categorical\n","np.random.seed(1234)\n","%matplotlib inline\n","import sys"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"M5P2FDhFSbIX"},"source":["## Iris Dataset\n","This example will use the popular \"Iris\" dataset.\n","\n","The [Iris dataset](http://scikit-learn.org/stable/auto_examples/datasets/plot_iris_dataset.html) was [originally introduced](http://en.wikipedia.org/wiki/Iris_flower_data_set) by Sir Robert Fisher in 1936 as an example for discriminant analysis.\n","The data focus on how to discriminate between three different types of the [iris flower](http://en.wikipedia.org/wiki/Iris_(plant) ):\n","\n","* Setosa, \n","* Versicolour, and\n","* Virginica\n","\n","Each row in the dataset contains the following features (measured in cm):\n","\n","* Sepal Length, \n","* Sepal Width, \n","* Petal Length, and \n","* Petal Width.\n","\n","The labels (true values) are mapped as integers in $[0,1,2]$ for the three different flower types. We will transform this via one-hot encoding to make the computations regarding the loss function easier later.\n","\n","As this is a popular dataset, it is contained in various machine learning packages.\n","Here we use the data from the [SciKit-Learn](https://scikit-learn.org/stable/) machine learning suite.\n","\n","Note that the dataset is quite small with only 150 observations. However, it has the benefit that the subsequent processing and network training is very fast, and it serves us well to illustrate the principles."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"f2Yj0J4eSZyI","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"cfe86247-4a2a-41c4-c438-9c0e059db1cd"},"source":["from sklearn.datasets import load_iris\n","iris = load_iris()\n","print('number of samples: {}'.format(len(iris.data)))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["number of samples: 150\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"hjlM7LEdmuAj","colab":{}},"source":["\n","# access the data and split into helper arrays.\n","x1 = iris.data\n","y1 = iris.target\n","\n","# The samples are ordered by target class # in the original dataset. \n","# As a first step, we shuffle the order before splitting the data into\n","# training and test data\n","perm = np.random.permutation(x1.shape[0])\n","y2 = y1[perm]\n","x2 = x1[perm,:]\n","\n","# now we take 90% of the data for trainig and 10% for testing\n","frac_train = 0.9\n","train_index = int(round(len(iris.data)*frac_train))\n","X_train = x2[0:train_index]\n","X_test  = x2[train_index+1 :]\n","\n","y_train = y2[0:train_index]\n","y_test  = y2[train_index+1 :]\n","\n","# convert the class number into one-hot encoding.\n","# e.g. target class 2 -> [0,0,1]\n","n_classes = 3\n","y_train = to_categorical(y_train, n_classes)\n","y_test = to_categorical(y_test, n_classes)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"BnhRqxXtbhlB"},"source":["## Forward and Backward Pass for Backpropagation\n","\n","This is the core of the neural network training. During the forward\n","pass we use the current settings of the weights and calculate the network response. During the backward pass in backpropagation, we comparet the output to the desired output and calculate the change of the weights.\n","\n","Note that we train the network such that during each weight update or learning step we present a batch of input signals to the network instead of just one.\n","For example, if we have four input variables, we do not just present ($x_1,x_2,x_3,x_4$) to the network to learn from this pattern, but each of $x_1,x_2,x_3$, and $x_4$ is a vector itself that contains $n$ training samples.\n","\n","### Forward Pass\n","We need to calculate the response of the network.\n","In our small network, we only need to compute the path from the input to the hidden layer and from the hidden to the output layer.\n","\n","* Input to hidden layer: \n","$a_1 = W_1 x + b_1$, $h_1 = f(a_1)$ where $f(.)$ is the activation function for the hidden layer. We will use the tanh(x) function here.\n","\n","* Hidden to output layer: \n","$a_2 = W_2 h_1 +  b_2$, $\\hat{y} = f_y(a_2)$ where $f_y(.)$ is the activation function for the output layer. We will use the sigmoid function here because it is more convenient in the backward pass.\n","The sigmoid function is given by: $ \\sigma(x) = \\frac{1}{1+e^{-x}}$\n","\n","### Backward Pass (Backpropagation)\n","The backward pass calculates the changes of the weights. We start by comparing how different the output of the current neural network (from the forward pass) is compared to what we expect (the true labels).\n","\n","Because we transformed the labels into one-hot encoded signals, we essentially perform three classifications at once: class 1: yes/no, class 2: yes/no, class 3: yes/no, one for each node.\n","For a single classification, the cross entropy or [log loss](https://scikit-learn.org/stable/modules/model_evaluation.html#log-loss) is given by:\n","LogL $= - (y \\log(\\hat{y}) + (1-y) \\log(1-\\hat{y}))$ where $y \\in {0,1}$ is the true label and $\\hat{y}$ is the prediction of the network. Since we use the sigmoid function, this is given by $p=\\sigma(x)$\n","\n","Recall that for the output layer the gradient used in the weight update is given by $\\frac{\\partial E}{\\partial W} = \\frac{\\partial E}{\\partial \\hat{y}} \\frac{\\partial \\hat{y}}{\\partial \\xi} \\frac{\\partial \\xi}{\\partial W}$.\n","Here, $\\xi$ is the output of the layer prior to the activation function, i.e.,\n","$\\xi = Wo_{i-1}+b$ and hence $\\frac{\\partial \\xi}{\\partial W} = o_{i-1}$, i.e.,\n","the output of the previous layer. \n","Using the chain rule, the first two partial derivatives evaluate to $y - \\hat{y}$ due to the special structure of the derivative of the sigmoid function (in fact, this is why we chose it here):  $\\sigma^\\prime(x) = \\sigma(x) \\left ( 1- \\sigma(x) \\right ) $\n","Hence the change of the weights is given by $\\delta W_2 = - (y-\\hat{y})h_1^T$\n","since we only have one hidden layer (denoted by $h_1$) and we need the transpose to do the matrix multiplication properly.\n","\n","The change of weights for the first (input) layer is calculated\n","in the same way using the error term $W_2^T (y-\\hat{y})$ and the derivative of the tanh(x) function used as activation function in the hidden layer ($\\tanh^\\prime(x) = 1 - \\tanh^2(x) $).\n","\n","For the biases $b_1$ and $b_2$, we can imagine that this is a special connection where the previous neuron  has a constant activation that is equal to one. Hence the backpropagation rule is reduced to delta_b = - learn_rate * 1 * error\n"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"ixU8WGx_bks4","colab":{}},"source":["#\n","# Forward pass: calculate network response\n","# N.B. need to append as many components to the bias b1 and b2\n","#      as we have elements in each training batch using np.tile \n","def forward_pass(W1, W2, b1, b2, x):\n","  #input to hidden layer\n","  a1 = np.matmul(W1,x) + np.tile(b1, x.shape[1])  \n","  h1 = np.tanh(a1)\n","\n","  #hidden to outpt layer\n","  a2 = np.matmul(W2, h1) + np.tile(b2, x.shape[1])\n","\n","  #output layer has sigmoid activation\n","  y_hat = expit(a2)\n","\n","  return a1, h1, a2, y_hat\n","\n","#\n","# Backward pass: calculate changes to weights\n","#\n","def backward_pass_backprop(e, h1, W2, a1, x):\n","  dW2 = -np.matmul(e, np.transpose(h1))                  \n","  da1 =  np.matmul(np.transpose(W2),e)*(1-np.tanh(a1)**2) \n","  dW1 = -np.matmul(da1, np.transpose(x))                  \n","\n","  # change in bias b1 and b2:\n","  db2 = -np.sum(e, axis=1)\n","  db1 = -np.sum(da1, axis=1)\n","\n","  return dW1, dW2, db1[:, np.newaxis], db2[:,np.newaxis]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"hFAuI8nWX2e6"},"source":["## Network training\n","\n","We now write the training loop for the small network.\n","The general structure is:\n","* loop over the number of epochs or training iteration\n"," * within each epoch, loop over all batches\n"," * compute the current network output (forward pass)\n"," * compute the error by comparing the output to the true labels\n"," * calculate the change of weights (backward pass)"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"rfnSVpPSX3VI","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"254dfd4f-4fd9-4775-b028-7a3878f09756"},"source":["#\n","# Network parameters\n","#\n","n_input  = 4\n","n_hidden = 100\n","n_output = n_classes\n","\n","batch_size = 32\n","learn_rate = 1e-4\n","n_epochs   = 100\n","\n","# we need to change the shape of the data from a long array \n","# with four variables per observation to an array with the four\n","# input variables, each with the observations (per variable)\n","# and accordingly for the output for the calculations of the weights.\n","x = np.transpose(X_train)\n","y = np.transpose(y_train)\n","\n","#\n","# initialize network weights\n","#\n","W1 = np.random.randn(n_hidden, n_input)\n","W2 = np.random.randn(n_output, n_hidden)\n","\n","b1 = np.random.randn(n_hidden, 1)\n","b2 = np.random.randn(n_output, 1)\n","\n","dataset_size = x.shape[1]\n","n_batches = dataset_size//batch_size\n","print('Dataset size: {}, batch_size: {}, number of batches {}'.format(dataset_size, batch_size, n_batches))\n","\n","# save the total error for each epoch, summed over all batches\n","train_error_epoch = []\n","\n","\n","\n","for i in range(n_epochs):\n","  #shuffle training data\n","  perm = np.random.permutation(x.shape[1])\n","  x = x[:, perm]\n","  y = y[:, perm]\n","\n","  # value of loss function and training error\n","  loss = 0.0\n","  train_error = 0.0\n","\n","  #\n","  # loop over batches\n","  #\n","  for j in range(n_batches):\n","    train_data = x[:, j*batch_size:(j+1)*batch_size]\n","    targets    = y[:, j*batch_size:(j+1)*batch_size]\n","    #\n","    # forward pass\n","    #\n","    a1, h1, a2, y_hat = forward_pass(W1=W1, W2=W2, b1=b1, b2=b2, x=train_data)\n","\n","    # metrics\n","    error = y_hat - targets\n","\n","    # due to one-hot encoding, each prediction and true label is an array\n","    # recover the class number via np.argmax\n","    preds = np.argmax(y_hat, axis=0) \n","    truth = np.argmax(targets, axis=0)\n","\n","    # error is the difference between prediction and true, summed over\n","    # all elements in the batch\n","    train_error += np.sum(preds!=truth)\n","\n","    # cross entropy loss\n","    loss_on_batch = log_loss(targets, y_hat)\n","\n","    #\n","    # calculate change of weights - backward pass\n","    #\n","    dW1, dW2, db1, db2 = backward_pass_backprop(e=error, h1=h1, W2=W2, a1=a1, x=train_data)\n","\n","    #weight update\n","    W1 += learn_rate * dW1\n","    W2 += learn_rate * dW2\n","    b1 += learn_rate * db1\n","    b2 += learn_rate * db2\n","    loss += loss_on_batch\n","\n","  #update errors per epoch\n","  training_error = 100.*train_error/x.shape[1]\n","  train_error_epoch.append(training_error)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Dataset size: 135, batch_size: 32, number of batches 4\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"0edXiNXZhbZY"},"source":["Plot the training error as the training progresses for each epoch"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"T84JKO-PZN29","colab":{"base_uri":"https://localhost:8080/","height":295},"outputId":"4a9c5b71-63d3-4275-c35b-6dee6359e77c"},"source":["x = range(0,n_epochs)\n","plt.plot(x, train_error_epoch, label='training error')\n","plt.title('Network training error')\n","plt.xlabel('Epochs')\n","plt.ylabel('Training error %')\n","#plt.legend(loc='best')\n","plt.show()"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAX4AAAEWCAYAAABhffzLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nO3dd5xU9bnH8c+zs7vs0tvSRUCK0sG1I2LvYom9xVhuEmNJrPHq1eSaqIm9XGND0Vhir0RBRBCMKCiC1KV32AWWztbn/jFn1wW2DGVmdme+79drXjvnzJlznjMHnvnNc875/czdERGR5JES7wBERCS2lPhFRJKMEr+ISJJR4hcRSTJK/CIiSUaJX0QkySjxS8Izsy/N7KoYbu8fZnbX3l5WZG9JjXcAUjeZ2UKgPtDZ3TcH864CLnH3IRG8/yVgqbvfGcUwd1mwX1e5++e7uw53/3U0lhXZW9Tilz0RAm6IdxBVsbC9+m/czBKusVTZ57Sr+5mIn0siU+KXPfF34GYza1rZi2a2v5mNMrO1ZjbbzM4L5l8DXAzcamabzOwjM7vCzD6q8N4cM3urwvQSM+sfPD/czL4zs/XB38MrLPelmf3FzCYAW4AuO8TU1symmtktlcT7CtAR+CiI61Yz62RmbmZXmtli4Itg2bfMbGUQwzgz61VhPS+Z2b3B8yFmttTMbjKz1Wa2wsyu2M1lWwSf1YZgv+81s/FVHRwzO9TMvjazfDP70cyGVPc5Bft5rZnlADnBcleb2dzgGH5oZu0qrGOn5aWOcHc99NjlB7AQOA54F7g3mHcV8GXwvAGwBLiCcElxAJAH9Axef6nsfcF0FyCfcGOkHbCIcCmo7LV1wWvNg+eXBuu9MJhuESz7JbAY6BW8nhbMuwroDMwBrqlpvypMdwIceDnYp8xg/q+ARkA94FFgSoX3lO8bMAQoBv4cxHIK4UTbbDeWfSN41Ad6Bp/v+Cr2oz2wJlhHCnB8MJ1VzefkwKjgM84EjgmO2cBgP58AxlXYxnbLx/vfpB6RP9Tilz31P8B1Zpa1w/zTgIXu/qK7F7v7D8A7wLmVrcTd5wMbgf7AYOAzYLmZ7Q8cBXzl7qXAqUCOu78SrPd1YBZweoXVveTu04PXi4J5PYExwN3u/uxu7Oc97r7Z3bcG8Q5z943uXgDcA/QzsyZVvLcI+LO7F7n7CGAT0GNXljWzEHBOEP8Wd58BDK8m3kuAEe4+wt1L3X0UMInwF0GZyj6n+9x9bbCfFwPD3P37YD//CBxmZp0qrKPi8lJHKPHLHnH3n4CPgdt3eGlf4JCgzJBvZvmEE0mbalY3lnCrd3Dw/EvCSf+oYBp+/jVQ0SLCLdwySypZ98XAMuDt6veoSuXrNLOQmd1vZvPMbAPhXwkALat47xp3L64wvQVouIvLZhFumVfct8r2s8y+wLk7fP6DgLY1vL/ivO0+a3ffRPhXQ02ftdRySvyyN9wNXM3OCWGsuzet8Gjo7r8JXq+sW9iyxH9k8HwsOyf+5YSTWkUdCSf1MpWt+x7CZYvXgtZzVarqrrbi/IuAoYRLXU0Il4MArJr17qlcwmWgDhXm7VPN8kuAV3b4/Bu4+/0VlqlsXyvO2+6zNrMGQAtq/qylllPilz3m7nOBfwHXV5j9MdDdzC41s7TgcZCZHRC8voodTrwSTu5HE64XLwW+Ak4inGx+CJYZEaz3IjNLNbPzCZdxPq4hzCLCZaYGwMvVXO1TWVw7agQUEG791gf+WsPye8zdSwifT7nHzOoHJbDLqnnLP4HTzezE4BdKRnDyuEM179nR68AVZtbfzOoR3s+J7r5wd/dDagclftlb/kw4qQLg7huBE4ALCLccVwIPED5JCPAC0DMoQ7wfvGcO4Zr2V8H0BmA+MCFIfLj7GsLnD24inHhvBU5z97yaAnT3QuBsoDUwrIrkfx9wZxDXzVWs6mXCJZBlwAzgm5q2vZf8jvAvjJXAK4QTc0FlC7r7EsK/Su4g/GthCXALu/B/3sP3MtxF+NzMCmA/wsdT6jhz1y81kbrIzB4A2rj75fGOReoWtfhF6ojgvoi+FnYwcCXwXrzjkrpHd9uJ1B2NCJd32hE+F/EQ8EFcI5I6SaUeEZEko1KPiEiSqROlnpYtW3qnTp3iHYaISJ0yefLkPHff8a76upH4O3XqxKRJk+IdhohInWJmO97lDqjUIyKSdJT4RUSSjBK/iEiSUeIXEUkySvwiIklGiV9EJMko8YuIJJmkSfyzVm5g9MxV8Q5DRCTukibx3/vxTK5+eRI/LsmPdygiInGVFIl/W1EJ3y5cS6nDzW/9yLaikvLXikpKydtU6VgWIiIJKSkS/6SF6ygsLuWXh3ciZ/UmHhudA8CiNZs56/8mMPhvY1i9YVucoxQRiY060VfPnho/N4+0kHHLiT3YWljCM2PnkZkW4rlx8zGDrUUlvPyfRdx8Yo94hyoiEnVJ0eIfPzeXAR2b0aBeKv992gG0bpzBw6PmsF+rhoy44UiOP6A1/5y4iK2FJTWvTESkjkv4xL92cyHTl29gUNeWADTOSOO5y7K589QDePO/DqNDs/pcPbgL+VuKeOf7pXGOVkQk+hI+8X89Lw93GNStZfm83u2bcNWRXUhPDe9+9r7N6NehCcPGL6C0VCOSiUhiS/jEP2FuHo0yUunbvkmVy5gZVx7Zhfl5mxkze3UMoxMRib2ETvzuzlc5eRzWpQWpoep39eTebWjXJIPnv1oQo+hEROIjoRP/4rVbWLpu63ZlnqqkhVK47PBO/Gf+Ghav2RKD6ERE4iOhE/9XOXkA5Sd2a3J8z9bh983NjVpMIiLxltCJf8LcPNo1yaBzywYRLd+lZQPaNslgwty8KEcmIhI/CX0D1+n92nFU9yzMLKLlzYxBXVsycsYqSkqdUEpk7xMRqUsSusV/Sp+2XHBwx116z6BuLVm/tYjpy9dHKSoRkfhK6MS/Ow7fL3w+oOz8gIhIoolq4jezpmb2tpnNMrOZZnaYmTU3s1FmlhP8bRbNGHZVVqN67N+mker8IpKwot3ifwz41N33B/oBM4HbgdHu3g0YHUzXKoO6tmTSwnXqu0dEElLUEr+ZNQEGAy8AuHuhu+cDQ4HhwWLDgTOjFcPuGtStJYUlpXy3cG28QxER2eui2eLvDOQCL5rZD2b2vJk1AFq7+4pgmZVA6yjGsFsO7tyc9FAK41XuEZEEFM3EnwoMBJ529wHAZnYo67i7A5X2imZm15jZJDOblJsb2xuq6qenMnDfpozXCV4RSUDRTPxLgaXuPjGYfpvwF8EqM2sLEPyttFc0d3/W3bPdPTsrKyuKYVZuUNeWzFixgbWbC2O+bRGRaIpa4nf3lcASMysb1upYYAbwIXB5MO9y4INoxbAnurZqCMDK9RqSUUQSS7Tv3L0OeNXM0oH5wBWEv2zeNLMrgUXAeVGOYbdkpIWA8LCMIiKJJKqJ392nANmVvHRsNLe7N5Ql/gIlfhFJMLpztwpliX9bsRK/iCQWJf4qZKSFP5ptRaVxjkREZO9S4q9CZlmNX3fvikiCUeKvgko9IpKolPirkJEaJH6VekQkwSjxV6FeeY1fLX4RSSxK/FWol5qCmRK/iCQeJf4qmBkZqSElfhFJOEr81chIS1GNX0QSjhJ/NTLS1OIXkcSjxF+NzLSQ+uoRkYSjxF+NemkhlXpEJOEo8VcjIy2FAt3AJSIJRom/GhmpIXXZICIJR4m/GpnpIXXZICIJR4m/GrqcU0QSkRJ/NXQDl4gkIiX+atTTdfwikoCU+KuRqcs5RSQBKfFXI1zjV4tfRBKLEn81MtJCFJc6RSVq9YtI4lDir0aG+uQXkQSkxF+NsnF3VecXkUSSGs2Vm9lCYCNQAhS7e7aZNQf+BXQCFgLnufu6aMaxu+qVJ361+EUkccSixX+0u/d39+xg+nZgtLt3A0YH07VS2YDr6q9HRBJJPEo9Q4HhwfPhwJlxiCEiGanhj2droUo9IpI4op34HRhpZpPN7JpgXmt3XxE8Xwm0ruyNZnaNmU0ys0m5ublRDrNymelBqUctfhFJIFGt8QOD3H2ZmbUCRpnZrIovurubmVf2Rnd/FngWIDs7u9Jloi1DNX4RSUBRbfG7+7Lg72rgPeBgYJWZtQUI/q6OZgx7IiNVV/WISOKJWuI3swZm1qjsOXAC8BPwIXB5sNjlwAfRimFPlV3Hr+EXRSSRRLPU0xp4z8zKtvOau39qZt8Bb5rZlcAi4LwoxrBHVOoRkUQUtcTv7vOBfpXMXwMcG63t7k3ll3Mq8YtIAtGdu9X4ucsG1fhFJHEo8VejrMWvGr+IJBIl/mqkhVJITTHV+EUkoSjx1yBDg7GISIJR4q9BRlqK7twVkYSixF+DeqkhthUq8YtI4og48ZvZoWb2qZl9aWa1tmO1vS0zPaQWv4gklCqv4zezNu6+ssKsPwBnAQZMBN6Pcmy1QnjcXdX4RSRxVHcD1z/M7Hvgb+6+DcgHfgGUAhtiEVxtkJEa0lU9IpJQqiz1uPuZwA/Ax2Z2GXAjUA9oQS3uQ39vy0gL6Tp+EUko1db43f0j4ESgCeHeNee4++PuHp8O8uNAl3OKSKKpMvGb2RlmNgb4lHCvmucDQ83sDTPbL1YBxltGWor66hGRhFJdjf9ewv3nZwKfufvBwE1m1g34C3BBDOKLO5V6RCTRVJf41wNnA/WpMFiKu+eQJEkfyq7qUeIXkcRRXY3/LMInclOBi2ITTu2TqRq/iCSYKlv87p4HPBHDWGqljLTwDVzuTjCojIhInaYuG2qQkRbCHQqK1eoXkcSgxF+Deqnhj6hA5R4RSRDVJn4zCwWXdCatzPRg3F311yMiCaKmG7hKgFIzaxKjeGqdjFQNuC4iiSWSwdY3AdPMbBSwuWymu18ftahqEQ2/KCKJJpLE/27wSEoacF1EEk2Nid/dh5tZOtA9mDXb3Ysi3YCZhYBJwDJ3P83MOgNvEL5HYDJwqbsX7nrosZGZplKPiCSWGq/qMbMhQA7wFPB/wBwzG7wL27gBmFlh+gHgEXfvCqwDrtyFdcVcPSV+EUkwkVzO+RBwgrsf5e6DCffW+UgkKzezDsCpwPPBtAHHAG8Hiwynlnfx/HOpR4lfRBJDJIk/zd1nl024+xwgLcL1PwrcSnjwFgiXd/LdvTiYXgq0r+yNZnaNmU0ys0m5ufHrBTqjvMWvGr+IJIZIEv9kM3vezIYEj+cI1+yrZWanAavdffLuBObuz7p7trtnZ2Vl7c4q9grV+EUk0URyVc+vgWuBsss3vyJc66/JEcAZZnYKkAE0Bh4DmppZatDq7wAs2+WoYyhDiV9EEky1iT+4IudHd98feHhXVuzufwT+GKxnCHCzu19sZm8RHrv3DeBy4IPdiDtmymr8W1XqEZEEEcmdu7PNrONe3OZtwB/MbC7hmv8Le3Hde53u3BWRRBNJqacZMN3MvmX7O3fPiHQj7v4l8GXwfD7hkb3qhJQUIz01RX31iEjCiCTx3xX1KGq5jNQU9c4pIgkjkhr/M0GNP2llpIXYWqgWv4gkhnjU+OucslG4REQSQUxq/HVdeNxdJX4RSQyq8UcgIy1Fd+6KSMKIpHfOsWa2L9DN3T83s/pAKPqh1R710kLqj19EEkYkvXNeTbhTtWeCWe2B96MZVG2TkRaiQIlfRBJEJH31XEu4+4UNAO6eA7SKZlC1TaZKPSKSQCJJ/AUVB0oxs1TAoxdS7aOrekQkkUSS+Mea2R1AppkdD7wFfBTdsGqXjFRdxy8iiSOSxH87kAtMA/4LGAHcGc2gapvwVT1K/CKSGCK5qqcUeC54JKWM9BDbilXjF5HEEEmLP+llpIYoLC6lpDSpTm2ISIJS4o9A2WAsBTrBKyIJQIk/Aj8PuK5yj4jUfTXW+M3sI3a+fHM94XF3n3H3bdEIrDbRuLsikkgiafHPBzbx8wneDcBGoDtJcsK3rNSjbhtEJBFE0knb4e5+UIXpj8zsO3c/yMymRyuw2uTnUo8Sv4jUfZG0+BtW7I8/eN4wmCys/C2JpV5Zi183cYlIAoikxX8TMN7M5gEGdAZ+a2YNgOHRDK622L9NI0IpxsgZq8ju1Dze4YiI7JFIbuAaYWbdgLLhF2dXOKH7aNQiq0XaNsnklD5teX3iYq4/thsN60XyfSkiUjtFejnngUAvoB9wnpldFr2QaqcrB3VmY0Exb363JN6hiIjskUj6438FeBAYBBwUPLIjeF+GmX1rZj+a2XQz+1Mwv7OZTTSzuWb2LzNL38N9iIn++zTloE7NGDZhge7gFZE6LZIWfzZwhLv/1t2vCx7XR/C+AuAYd+8H9AdOMrNDgQeAR9y9K7AOuHJ3g4+1Kwd1Yem6rYycvjLeoYiI7LZIEv9PQJtdXbGHbQom04KHA8cQHtELwieHz9zVdcfL8T1b07F5fZ4fvyDeoYiI7LZIEn9LYIaZfWZmH5Y9Ilm5mYXMbAqwGhgFzAPy3b04WGQp4aEcK3vvNWY2ycwm5ebmRrK5qAulGL86ohOTF63jX98tjnc4IiK7JZLLU+7Z3ZW7ewnQ38yaAu/x85VBkbz3WeBZgOzs7FpTVD//oI78+6eV3PbONCYtXMefh/YmMz2pxp4XkToukss5x+7pRtw938zGAIcBTc0sNWj1dwCW7en6YykzPcSrVx3CY6NzeHLMXKYsyeefVx1C68YZ8Q5NRCQiVZZ6zGx88HejmW2o8NhoZhtqWrGZZQUtfcwsEzgemAmMAX4RLHY58MGe7kSspYZSuOmEHgy/4mByVm/i3e/r1HeXiCS5Klv87j4o+NtoN9fdFhhuZiHCXzBvuvvHZjYDeMPM7gV+AF7YzfXH3eDuWbRvmsn05evjHYqISMQiugU1SN6tKy7v7tWe3XT3qcCASubPBw7etTBrr17tGjNjeY0/gEREao1I+uO/DrgbWAWUjUTiQN8oxlVn9GrXhFEzV7G5oJgG6spBROqASDLVDUAPd18T7WDqol7tGuMOM1dsUAduIlInRHId/xLCI25JJXq1bwzAdJV7RKSOiKTFPx/40sw+IdwNAwDu/nDUoqpD2jTOoHmDdJ3gFZE6I5LEvzh4pAcPqcDM6NWusVr8IlJnRHID159iEUhd1rNdY4aNX0BhcSnpqZH2dC0iEh9VJn4ze9TdbzSzjwhfxbMddz8jqpHVIb3aNaGoxJm7ehM92zWOdzgiItWqrsX/SvD3wVgEUpf1bFt2gne9Er+I1HrV3bk7Ofi7x331JLrOLRuQmRZi+vINnBvvYEREahDJDVzdgPuAnkB5T2Tu3iWKcdUpoRTjgLaNdAeviNQJkZyJfBF4GigGjgZeBv4ZzaDqol7tmjBjxQZKNSyjiNRykST+THcfDZi7L3L3e4BToxtW3dOrXWM2FRSzeO2WeIciIlKtSBJ/gZmlADlm9jszOwtoGOW46pxe7ZoAuoNXRGq/SBL/DUB94HrgQOASwv3oSwXd2zSkSWYawyYsoETlHhGpxapN/EF3zOe7+yZ3X+ruV7j7Oe7+TYziqzPqpYa4+/SeTF60jhcnaDB2Eam9qhuBKzUYM3dQDOOp084a0J7jDmjF3z+bzbzcTfEOR0SkUtW1+L8N/v5gZh+a2aVmdnbZIxbB1TVmxl/P6kNGWohb3vpRJR8RqZUiqfFnAGuAY4DTgNODv1KJVo0z+NMZvfh+cT73fDidwuLSmt8kIhJD1d3A1crM/gD8RLivHqvwmpqy1Rjavx3Tlq3nhfELmLZsPU9eNIAOzerHOywREaD6Fn+I8GWbDYFGFZ6XPaQKZsZdp/Xk/y4eyLzVmzjlsa8YOX1lvMMSEQGqb/GvcPc/xyySBHRKn7b0ateY3732A9e8MplfHdGZ20/eX103i0hcVZeBrJrXJEL7tmjA2785jF8e3olhExZw7j++Zuk63d0rIvFTXeI/dk9WbGb7mNkYM5thZtPN7IZgfnMzG2VmOcHfZnuynbqgXmqIe87oxT8uGcj83M3c+f5P8Q5JRJJYlYnf3dfu4bqLgZvcvSdwKHCtmfUEbgdGu3s3YHQwnRRO6t2Wcw7swH/mrWFbUUm8wxGRJBW1YrO7r3D374PnG4GZQHtgKDA8WGw4cGa0YqiNjuzWkoLiUr5ftC7eoYhIkorJWUYz6wQMACYCrd19RfDSSqB1Fe+5xswmmdmk3NzcWIQZE4d0aUFqivHV3Lx4hyIiSSrqid/MGgLvADe6+3ZdV7q7U8U9Ae7+rLtnu3t2VlZWtMOMmYb1UhnQsSkTlPhFJE6imvjNLI1w0n/V3d8NZq8ys7bB622B1dGMoTYa1DWLacvWs25zYbxDEZEkFLXEb2YGvADMdPeHK7z0IT9363w58EG0YqitBnVrgTv8Z/6aeIciIkkomi3+I4BLgWPMbErwOAW4HzjezHKA44LppNKvQ1Ma1kvlqxyVe0Qk9mocbH13uft4qr4JbI/uEajrUkMpHNqlher8IhIX6jsgTo7s1pLFa7eweI3u4hWR2FLij5MjurYEYLxa/SISY0r8cbJfVgPaNsngq5zEuUdBROoGJf44MTOG9GjF2Dm56r5BRGJKiT+OTuvbli2FJXw5O+luZRCROFLij6NDOjenRYN0Pp66ouaFRUT2EiX+OEoNpXBi7zZ8MWs1WwtV7hGR2FDij7PT+qjcIyKxpcQfZweXlXumqdwjIrGhxB9nqaEUTurdhi9mqtwjIrGhxF8LnNqnLVuLShijco+IxIASfy1wcOfmtGyYzie6ukdEYkCJvxYoL/fo6h4RiQEl/lriFJV7RCRGlPhriUM6t1C5R0RiQom/lgilGCf3bsvoWavYUli83WvhoYlFRPYOJf5a5JQ+bdlWVMqYWT/32PnUmLkMemAM4zVal4jsJUr8tUj46p56fDJtOQBTl+bz8Kg55G0q4NJhE3l45GxKStX6F5E9o8Rfi4TLPeGre/K3FHLzWz/SsmE6Y285mnMGduDxL+Zy6QsTKSjWlT8isvuU+GuZU/uGyz2XDfuWOas2cf/ZfWnTJIMHz+3HfWf34et5a3h8dE68wxSROkyJv5Y5qFNzshrVY+rS9Zx7YAeO3r9V+WsXHtyRXxzYgX+Mnc/UpflxjFJE6jIl/lomlGKcM7AD+zTP5M7Teu70+l2n9SSrYT1ufutHlXxEZLdELfGb2TAzW21mP1WY19zMRplZTvC3WbS2X5fddlIPvrhpCE0y03Z6rUlmGved04c5qzbx4GezWZa/lWX5W1m/pSgOkYpIXRTNFv9LwEk7zLsdGO3u3YDRwbTswMxIC1V9aI7u0Yrzsjvw3FcLOOL+Lzji/i846C+fa+B2EYmIRfPmIDPrBHzs7r2D6dnAEHdfYWZtgS/dvUdN68nOzvZJkyZFLc66aFtRCSNnrGJb0LfPM+PmsbWwhE9/P5jGGTv/UhCR5GNmk909e8f5qTGOo7W7l/VJsBJoXdWCZnYNcA1Ax44dYxBa3ZKRFuKMfu3Kp7u1bsg5T3/NXz+Zyf3n9AXgxyX5/GXETDZsDZeBQinGPWf04qBOzeMSs4jUDnE7uevhnxpV/txw92fdPdvds7OysmIYWd00oGMzrh7chTe+W8KXs1czbPwCfvGPr1mydgv7tqjPvi3qs3jNFl76emG8QxWROIt1i3+VmbWtUOpRV5R70e+P687omau5+uVJFJU4xx3QmgfP7UvT+ukA/Pd703j3+2VsLSwhMz0U52hFJF5i3eL/ELg8eH458EGMt5/QMtJCPHRuP1o1yuDOUw/gucsOLE/6EL45TF0/i0jUWvxm9jowBGhpZkuBu4H7gTfN7EpgEXBetLafrPrt05QJtx9T6WsVu34+pU/bGEcmIrVF1BK/u19YxUvHRmubUr1QinFS7za8M3kZWwqLqZ8e60qfiNQGunM3yZzap1243DNL1/yLJCsl/iRT1vXziGk7j/RVUupc+9r3PDN2XhwiE5FYUeJPMmVdP1c20tcL4+fzydQVPPp5DvlbCuMUoYhEmxJ/Eiob6euDKcvL581dvYkHR86h3z5N2VpUwmvfLt5r25uzaiP3jZjJ6g3b9to6d8eEuXk8PGrOTl94IslGiT8JHdy5Ob3aNeaO96bx8Kg5FBaXcsvbP1I/PcRzlx3IoK4tGf71QgqLS/doO+7Om5OWcMaT43lm3HxOefyruPQnVFxSyoOfzeaSFyby+Ogchj45gTmrNsY8DpHaIqp99ewt6qtn79tSWMz/fDCdtycvpX3TTJblb+WxC/oztH97vpy9ml+++B2PnN+PswZ0AGDpui0UFJeyX1bD7dazdnMhE+evqfQW7M9nrOLdH5ZxWJcWXHdsV+7+YDpzczdxzZFd6LdPUwDqp4c4slsWoRTb5X2Yl7uJ2St/TuA92zamU8sG2y2zasM2rnv9B75dsJZzD+zAib3acPu7U9lUUMz/Du3Nudn7RLQtd+freWtYv3XnXlBTzDiqe1bEN8Wt3rCNguJS9mleP6LlRXZXVX31KPEnubcnL+Wu93/i6P2zeOqigZgZ7s4Jj4wjLZTCJ9cP4oMpy7njvWkUlZRyxykH8MvDO2FmfD03jxv+NYXcjQWVrtsMbji2G9cd041QirGlsJi7P5jOW5OXbrfcb4bsx20n7R9xzO7OixMWct+/Z1JU8vO/3/TUFP7ntJ5cfEhHzIyxc3L5w7+msKWwhL+c1ZuzB4a/xFZv2MYNb0zhP/PXcPbA9tx7Zu9qL21dv6WIW97+kZEzVlW5zFHds3jpioMwq/4LzN0Z+tQE8rcUMfaWITUuL7InlPilSuu3FtEgPURqha6g3/h2Mbe/O40ju7Xkq5w8Du7UnMaZqXw+czUn9mpNj9aNeGLMXLq0bMC9Z/aheYP0ndbbJDONNk0ydpq/eM0WthYFvYqOncf7U5bx7m+PoH/wKwDCVxgVl+5catq0rZg/vjuNkTNWcdwBrfn98d1ITUmhqKSUv382m7Fzcjm1b1s6Nq/P01/Oo0frRjx18UC6ttr+l0pJqfPEFzk8NjqHLi0b8MSFA9mvVYOdtjd9+Qauf/0HVq7fxm0n7c/g7jv3G/X5zFX8/bPZ/O2cvpx3UPW/ICbOX8P5z34DwAfXHlH+y6euc9t+riwAABAZSURBVHd9idVCSvyyS7YVlXDE/V+wdksh1w7pyo3HhVvtL4xfwP3/nkVxqXP2wPb879DeNKi3+zeCbdhWxImPjKNBvVQ+vm4QGWkhRk5fye3vTmPt5sqvLEoLGbeffAC/OqLTdsmmtNR5Ztx8Hhw5m5JS54KD9uHu03tVW4L5em4e178xhbxNlf9qAWjfNJMnLxrAgI6VjxtUWupc9Pw3TF+2gc9+P5h2TTOrXNfVL0/iu4Vr2VxQzBVHdOaOUw6oclkIH4f7Rsxk1IxVfHjdIFo2rFft8vHw2sTFPDVmLm9cc6jKV7WMEr/ssilL8ikpLeXAfbfvxvmnZetZsX4bx/esslftXTJ2Ti6XD/uWKwd1xh2GTVhA7/aNObl35d1KHNU9i97tm1S5vh+X5LNmcwHH7B9ZfLkbC3j/h2UUluz8C6NeagrnHrgPTepXP8bB4jVbOOmxcWR3as7wKko+C/I2c8xDX3Ld0V35afkGZq/cyPjbjq6ypbwwbzPXvvY905dvAOB/z+zNpYfuG9E+xcqCvM2c/Ng4thWVcliXFrx61SGk7Mb5GomO2tIfv9Qh/asoQ/Ru36TaxLurjuqexQUH7cML4xcA8MvDO/HHU/anXuru9SC6q+WTrEb1uHpwl93aVpmOLerzx5P3564PpnPO01+XnzM4qnsWVw7qTEqKMWz8AtJSUrjksH0ZNyePL2at5sel6yv9nD+eupzb35lGKMV47rJs7v/3TEZMXbHLib+opJQ/fzSDBXmbgfB5l9P7tuPc7A7lXzjbikp4bHQODeul8uuj9ov4RHtJqXPLWz+SHkrht0O68vCoObw6cRGXHtYJgB8Wr+Of3yzmtpN70KrRziU/gILiEv780QwGd8/ixF5tyudv3FbE3z+bTbfWjbgkOGcTK/lbCvnbZ7O5alBnulS4mKGopJS/jpjJqX3akl3Hx7RQ4pda4b9PPYCtRSWc3LstJ/VuU/MbaqGLD9mX+Xmbmbp0PVuLSthcUMxfRsxkXE4ud5/ei7cmL2Fo/3a0apTB8T1bkxYyPpm6fLvEv62ohHs/mcE/v1nMgI5NeeLCAXRoVp9pS/N5csxccjcWkNUo8nLPU2Pm8so3i+i3T1NSU4z8LYXc+s5Uxs/N469n9yFvY8F2vyrGzcnl8QsH0Lpx5Ym6ohcnLGDSonU8dG4/zh7YnkmL1nHfv2dxVPdWjJyxsrwkuH5rIc9dll1p8n708xxenbiYVycuLv/Cz1m1iWtf+55Fa7YAMCEnjwd+0bfSMaij4U8fzeC9H5Yxbel63v3t4eXDoD795TxenLCQEdNWMPLGo2r8FVibqdQjEiXuzuvfLuGej6ZTWuoUlzqf3ngk+7dpDMCvXvpuu3LPgrzNXPvq98xYsYH/GtyFm0/sUZ50Zq/cyImPjquy3FNS6oyasZLD9mtZniCnL1/P0CcncFrftjx6wQAgfD7i6bHzeGjkbDo0q8/azYWEUoyHzu1H/tYi7nr/J+qnh7h6cBfqpVZ9m09xifPgyNkM6tqS5y8PJ/Xl+Vs58ZFxAGwsKOaEnq3p2a4xj36ew8Pn9Su/qqrMlCX5nP1/EzhrQAeaZKYxbMICurZqyOI1W2jRMJ3HLxzAlMX5PPDpLNo0yeAflxxY7S/Nuas38lVOXo3HpWn9NE7v2267ixnKjJy+kmtemczh+7Xg63lruPmE7vzumG7MXLGBM54cz4COzZi8aB1n9m/PQ+f1q3FbFeWs2siGbUU7lU6jSaUekRgzMy46pCP992nK9W/8QNeshuVJH+DUPm35YtZqpizJZ/HaLdzx7jTSUlN44fJsjj1g+/MT3Vs3ZL+sBnwydXmlif/FCQu495OZdGiWyZMXDaRn28bc/NZUmjVI554zepUvl5JiXHt0V7L3bcYNb0yhR5tGPH7hANoHJ6T7dWjC7177gfv/PavG/WvTOIO/nt2nvCXfrmkm95zRizvf/4m7T+/JLw/vRKnD+Jw87vlwOkd0bVn+S2JbUQk3vTmF1o0zuPuMnjTOSOOQLs259e2pDOrWkgfP7UfzBukc1Kk5B3ZqxrWvfs/VL0/is0rGlC77gv3TR9MpiPCmw9cnLuHxCwdsd9XZus2F3PHeTxzQtjEvXXEwv39zCo+NzmFIj1bc9s5UmmSm88wlBzJswgKe+GIuJ/duw3ERnOdyd175ZhH3fjwTgE+uH0S31o0iijNa1OIXiQF3x53tTnyu31pE9r2jaN04g6XrtnLgvs144sIBVV4V9PCoOTz5RQ7f3HHsdjXzebmbOOWxr+jXoSnL8reyeuM2DuncgvFz83jusuwqT8IXl5QSSrGdSjClpc6GbTvfqLaj+umppFfyq6Ck1Lc7T1B2AviwLi340xm9AXjp64UMm7CA4b86mKMqXCJbXFJaaUu87NfBuQfuwwO/6Fs+f1NBMXe8O40Pf1zOkd1a8tez+tAoo/r27BezVnPn+z+RkRbivrP7cEDwZfz3kbP597QVfPC7I+jVrglrNhVwwiPj2FpUwpbCEp659EBO7NWGwuJSznhyPGs3F/LPqw4ho5pzUUWlpTw0cjYjpq3kqO5ZTF2aT8fm9XnnN4eX76e7s3TdVqpKxW2aZFT6OUdCV/WI1EJXDZ/E5zNX8euj9uOmE7qXl3YqU17uGdqr/ARqSalz7j++Zl7uZkb9fjDpqSnc/NZUPp+5irMGtOeR8/vHaE+q98L4BfzvxzO2m3fBQftw/zl9q3jHzh74dBZPfzmPl644iCE9WjFj+YbgXMBm/nB8d347pGvEVxTNXb2J3732PbNWbt91x43HdePG47qXT/972gp+8+r3DO3fjseCchmEr2wb+tQESkprzp+hFOPWE3tw9ZFd+GTaCq57/QduPakHvx3SldUbtnH9Gz/wzfy1Vb7/8z8ctdN9KJFS4hephXI3FrB64zZ6tav5Kil35/hHxtGiQTr/+q/DAHh23Dz+OmIWj57fnzMHtC9f7j/z1jBw32ZkpNWOsZVLS52xc3LL783ISAtxXM9Wu3TlVkFxCac9Pp6N24q5enAXHvh0Fs3qp/HYBQM4tEuLXY5pW1EJn89cRUFRuDzUODONY/ZvtdNVTZMXraNXu8Y7fZY/LVu/XZchVenZrjEHtA3/qnB3fvvq94yeuZq7Tu/JY5/PYXNBCdcf241WVZy0P75X653KW5FS4hdJAA+PmsMTX+TQNbjMcOGazRzdoxXPXHpgUtw5++OSfM5++mtKSp3B3bN45Lx+tKiFN7VVJy8oIa3dXEj31g156qKBUav56+SuSAK4+JCOLF6zufxmswP3bcbNJ/ZIiqQP4Xs0/nZOXzYVFHPpofvWyZvFWjasx1MXDWTC3DyuPbprxJ377U1q8YuIJKiqWvzqj19EJMko8YuIJJm4JH4zO8nMZpvZXDO7PR4xiIgkq5gnfjMLAU8BJwM9gQvNrGes4xARSVbxaPEfDMx19/nuXgi8AQyNQxwiIkkpHom/PbCkwvTSYN52zOwaM5tkZpNyc2M/QLeISKKqtSd33f1Zd8929+ysrJ2HuxMRkd0Tj8S/DKg4MGmHYJ6IiMRAzG/gMrNUYA5wLOGE/x1wkbtPr+Y9ucCi3dxkS6DmTroTTzLudzLuMyTnfmufI7Ovu+9UMol5lw3uXmxmvwM+A0LAsOqSfvCe3a71mNmkyu5cS3TJuN/JuM+QnPutfd4zcemrx91HACPisW0RkWRXa0/uiohIdCRD4n823gHESTLudzLuMyTnfmuf90Cd6J1TRET2nmRo8YuISAVK/CIiSSahE38y9AJqZvuY2Rgzm2Fm083shmB+czMbZWY5wd9m8Y51bzOzkJn9YGYfB9OdzWxicLz/ZWbp8Y5xbzOzpmb2tpnNMrOZZnZYoh9rM/t98G/7JzN73cwyEvFYm9kwM1ttZj9VmFfpsbWwx4P9n2pmA3dlWwmb+JOoF9Bi4CZ37wkcClwb7OftwGh37waMDqYTzQ3AzArTDwCPuHtXYB1wZVyiiq7HgE/dfX+gH+H9T9hjbWbtgeuBbHfvTfjenwtIzGP9EnDSDvOqOrYnA92CxzXA07uyoYRN/CRJL6DuvsLdvw+ebyScCNoT3tfhwWLDgTPjE2F0mFkH4FTg+WDagGOAt4NFEnGfmwCDgRcA3L3Q3fNJ8GNN+H6jzOCu//rAChLwWLv7OGDtDrOrOrZDgZc97BugqZm1jXRbiZz4I+oFNJGYWSdgADARaO3uK4KXVgKt4xRWtDwK3AqUBtMtgHx3Lw6mE/F4dwZygReDEtfzZtaABD7W7r4MeBBYTDjhrwcmk/jHukxVx3aP8lsiJ/6kYmYNgXeAG919Q8XXPHzNbsJct2tmpwGr3X1yvGOJsVRgIPC0uw8ANrNDWScBj3Uzwq3bzkA7oAE7l0OSwt48tomc+JOmF1AzSyOc9F9193eD2avKfvoFf1fHK74oOAI4w8wWEi7hHUO49t00KAdAYh7vpcBSd58YTL9N+IsgkY/1ccACd8919yLgXcLHP9GPdZmqju0e5bdETvzfAd2Cs//phE8IfRjnmPa6oLb9AjDT3R+u8NKHwOXB88uBD2IdW7S4+x/dvYO7dyJ8XL9w94uBMcAvgsUSap8B3H0lsMTMegSzjgVmkMDHmnCJ51Azqx/8Wy/b54Q+1hVUdWw/BC4Lru45FFhfoSRUM3dP2AdwCuEuoOcB/x3veKK0j4MI//ybCkwJHqcQrnmPBnKAz4Hm8Y41Svs/BPg4eN4F+BaYC7wF1It3fFHY3/7ApOB4vw80S/RjDfwJmAX8BLwC1EvEYw28Tvg8RhHhX3dXVnVsASN81eI8YBrhq54i3pa6bBARSTKJXOoREZFKKPGLiCQZJX4RkSSjxC8ikmSU+EVEkowSvyQtMysxsykVHnutczMz61Sxl0WR2iQug62L1BJb3b1/vIMQiTW1+EV2YGYLzexvZjbNzL41s67B/E5m9kXQ//loM+sYzG9tZu+Z2Y/B4/BgVSEzey7oS36kmWUGy18fjJ8w1czeiNNuShJT4pdklrlDqef8Cq+td/c+wJOEewIFeAIY7u59gVeBx4P5jwNj3b0f4b5zpgfzuwFPuXsvIB84J5h/OzAgWM+vo7VzIlXRnbuStMxsk7s3rGT+QuAYd58fdIC30t1bmFke0Nbdi4L5K9y9pZnlAh3cvaDCOjoBozw8gAZmdhuQ5u73mtmnwCbCXS687+6boryrIttRi1+kcl7F811RUOF5CT+fUzuVcD8rA4HvKvQyKRITSvwilTu/wt//BM+/JtwbKMDFwFfB89HAb6B8HOAmVa3UzFKAfdx9DHAb0ATY6VeHSDSppSHJLNPMplSY/tTdyy7pbGZmUwm32i8M5l1HePSrWwiPhHVFMP8G4Fkzu5Jwy/43hHtZrEwI+Gfw5WDA4x4ePlEkZlTjF9lBUOPPdve8eMciEg0q9YiIJBm1+EVEkoxa/CIiSUaJX0QkySjxi4gkGSV+EZEko8QvIpJk/h9UGRcUVZPfNAAAAABJRU5ErkJggg==\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"qXW2zNw9hjRV"},"source":["Check the predictions with the independent test sample"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"yAexk359qgDv","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"964dcea7-9893-4d9a-f846-785db69d943e"},"source":["test_samples = np.transpose(X_test)\n","test_targets = np.transpose(y_test)\n","    \n","y_hats = forward_pass(W1, W2, b1, b2, test_samples)[-1]\n","preds = np.argmax(y_hats, axis=0) \n","truth = np.argmax(test_targets, axis=0)\n","test_error = 1.*np.sum(preds!=truth)/preds.shape[0]\n","\n","print('Test error:', test_error, '%')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Test error: 0.0 %\n"],"name":"stdout"}]}]}
